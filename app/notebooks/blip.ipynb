{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7HxFeCIEQ1D"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoProcessor, BlipForQuestionAnswering\n",
        "import os\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgXa-I9zNIZK"
      },
      "outputs": [],
      "source": [
        "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmN7j2tSQb6z"
      },
      "outputs": [],
      "source": [
        "text = \"List all the measurements in this image. For example, 100 grams or 1000 kgs. List only the measurement, nothing else. Print <NO> if the measurement cant be found\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOyt3HQdQw4J"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "sample = df.iloc[:300]\n",
        "\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "test_sample = test_df.iloc[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiPCnHkwRvhH",
        "outputId": "77f5a415-61b7-47c3-c3c8-6e674cd8ab3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: https://m.media-amazon.com/images/I/61I9XdN6OFL.jpg\n",
            "1: https://m.media-amazon.com/images/I/71gSRbyXmoL.jpg\n",
            "2: https://m.media-amazon.com/images/I/61BZ4zrjZXL.jpg\n",
            "3: https://m.media-amazon.com/images/I/612mrlqiI4L.jpg\n",
            "4: https://m.media-amazon.com/images/I/617Tl40LOXL.jpg\n",
            "5: https://m.media-amazon.com/images/I/61QsBSE7jgL.jpg\n",
            "6: https://m.media-amazon.com/images/I/81xsq6vf2qL.jpg\n",
            "7: https://m.media-amazon.com/images/I/71DiLRHeZdL.jpg\n",
            "8: https://m.media-amazon.com/images/I/91Cma3RzseL.jpg\n",
            "9: https://m.media-amazon.com/images/I/71jBLhmTNlL.jpg\n",
            "10: https://m.media-amazon.com/images/I/81N73b5khVL.jpg\n",
            "11: https://m.media-amazon.com/images/I/61oMj2iXOuL.jpg\n",
            "12: https://m.media-amazon.com/images/I/91LPf6OjV9L.jpg\n",
            "13: https://m.media-amazon.com/images/I/81fOxWWWKYL.jpg\n",
            "14: https://m.media-amazon.com/images/I/81dzao1Ob4L.jpg\n",
            "15: https://m.media-amazon.com/images/I/91-iahVGEDL.jpg\n",
            "16: https://m.media-amazon.com/images/I/81S2+GnYpTL.jpg\n",
            "17: https://m.media-amazon.com/images/I/81e2YtCOKvL.jpg\n",
            "18: https://m.media-amazon.com/images/I/81RNsNEM1EL.jpg\n",
            "19: https://m.media-amazon.com/images/I/91prZeizZnL.jpg\n",
            "20: https://m.media-amazon.com/images/I/31EvJszFVfL.jpg\n",
            "21: https://m.media-amazon.com/images/I/61wzlucTREL.jpg\n",
            "22: https://m.media-amazon.com/images/I/61sQ+qAKr4L.jpg\n",
            "23: https://m.media-amazon.com/images/I/81x77l2T5NL.jpg\n",
            "24: https://m.media-amazon.com/images/I/71nywfWZUwL.jpg\n",
            "25: https://m.media-amazon.com/images/I/71nywfWZUwL.jpg\n",
            "26: https://m.media-amazon.com/images/I/51WsuKKAVrL.jpg\n",
            "27: https://m.media-amazon.com/images/I/61XGDKap+JL.jpg\n",
            "28: https://m.media-amazon.com/images/I/715vVcWJxGL.jpg\n",
            "29: https://m.media-amazon.com/images/I/613v+2W4UwL.jpg\n",
            "30: https://m.media-amazon.com/images/I/71+fn9TWQmL.jpg\n",
            "31: https://m.media-amazon.com/images/I/71aKgRRQ2wL.jpg\n",
            "32: https://m.media-amazon.com/images/I/71rKXZJrh4L.jpg\n",
            "33: https://m.media-amazon.com/images/I/71D824lbRvL.jpg\n",
            "34: https://m.media-amazon.com/images/I/71004c9tzfL.jpg\n",
            "35: https://m.media-amazon.com/images/I/51bQPPtMqYL.jpg\n",
            "36: https://m.media-amazon.com/images/I/61o2ntPNNgL.jpg\n",
            "37: https://m.media-amazon.com/images/I/61o2ntPNNgL.jpg\n",
            "38: https://m.media-amazon.com/images/I/71IUuTJ8QwL.jpg\n",
            "39: https://m.media-amazon.com/images/I/915JHkwtcrL.jpg\n",
            "40: https://m.media-amazon.com/images/I/71cjrYndwIL.jpg\n",
            "41: https://m.media-amazon.com/images/I/81hnk2WXO3L.jpg\n",
            "42: https://m.media-amazon.com/images/I/61HXgujoxpL.jpg\n",
            "43: https://m.media-amazon.com/images/I/613G8GOyLSL.jpg\n",
            "44: https://m.media-amazon.com/images/I/71YyZ2iPyZL.jpg\n",
            "45: https://m.media-amazon.com/images/I/81K3JwUCnQL.jpg\n",
            "46: https://m.media-amazon.com/images/I/41wvffSxB4L.jpg\n",
            "47: https://m.media-amazon.com/images/I/91cErO-KbLL.jpg\n",
            "48: https://m.media-amazon.com/images/I/817vo3DcCNL.jpg\n",
            "49: https://m.media-amazon.com/images/I/61AHQ35poHL.jpg\n",
            "50: https://m.media-amazon.com/images/I/61WFh8RCQYL.jpg\n",
            "51: https://m.media-amazon.com/images/I/711SATIDrmL.jpg\n",
            "52: https://m.media-amazon.com/images/I/61x6RSjwQIL.jpg\n",
            "53: https://m.media-amazon.com/images/I/613BeFNwHcL.jpg\n",
            "54: https://m.media-amazon.com/images/I/61hWZdkq6WL.jpg\n",
            "55: https://m.media-amazon.com/images/I/71E7CU55dcL.jpg\n",
            "56: https://m.media-amazon.com/images/I/61c+hSNnnZL.jpg\n",
            "57: https://m.media-amazon.com/images/I/915w0BdW-gL.jpg\n",
            "58: https://m.media-amazon.com/images/I/61sx0ezNNLL.jpg\n",
            "59: https://m.media-amazon.com/images/I/71ldprwbKrL.jpg\n",
            "60: https://m.media-amazon.com/images/I/71E9iF-bmKL.jpg\n",
            "61: https://m.media-amazon.com/images/I/71sWRp1SNwL.jpg\n",
            "62: https://m.media-amazon.com/images/I/61Fwq4GeTmL.jpg\n",
            "63: https://m.media-amazon.com/images/I/61-oj+N+BxL.jpg\n",
            "64: https://m.media-amazon.com/images/I/71e6kJLE+LL.jpg\n",
            "65: https://m.media-amazon.com/images/I/71SuzaRS7gL.jpg\n",
            "66: https://m.media-amazon.com/images/I/71nsfFCXF0L.jpg\n",
            "67: https://m.media-amazon.com/images/I/71hgN7yu9OL.jpg\n",
            "68: https://m.media-amazon.com/images/I/61SmT8pkLtL.jpg\n",
            "69: https://m.media-amazon.com/images/I/71ZtDgGX+iL.jpg\n",
            "70: https://m.media-amazon.com/images/I/413FQB0ZMLL.jpg\n",
            "71: https://m.media-amazon.com/images/I/41EjbFu-+yL.jpg\n",
            "72: https://m.media-amazon.com/images/I/71dWDwMhWmS.jpg\n",
            "73: https://m.media-amazon.com/images/I/61d6Kj80QSL.jpg\n",
            "74: https://m.media-amazon.com/images/I/71bvOuz9w1L.jpg\n",
            "75: https://m.media-amazon.com/images/I/71l0M0tMGjL.jpg\n",
            "76: https://m.media-amazon.com/images/I/71Lpqdrpi4L.jpg\n",
            "77: https://m.media-amazon.com/images/I/71jLIbCcwOL.jpg\n",
            "78: https://m.media-amazon.com/images/I/718EdwGgyVL.jpg\n",
            "79: https://m.media-amazon.com/images/I/713twQgCHSL.jpg\n",
            "80: https://m.media-amazon.com/images/I/61I0O1qJbhS.jpg\n",
            "81: https://m.media-amazon.com/images/I/61eOO5IW4NL.jpg\n",
            "82: https://m.media-amazon.com/images/I/716AQpAJjZL.jpg\n",
            "83: https://m.media-amazon.com/images/I/71FVeRd2jqL.jpg\n",
            "84: https://m.media-amazon.com/images/I/81njuNSPdjL.jpg\n",
            "85: https://m.media-amazon.com/images/I/51xfRlxWIXL.jpg\n",
            "86: https://m.media-amazon.com/images/I/71duwM3SjpL.jpg\n",
            "87: https://m.media-amazon.com/images/I/612xIhPMHqL.jpg\n",
            "88: https://m.media-amazon.com/images/I/51b9JEHOriL.jpg\n",
            "89: https://m.media-amazon.com/images/I/81lgxfKqUUL.jpg\n",
            "90: https://m.media-amazon.com/images/I/814sAvV89SL.jpg\n",
            "91: https://m.media-amazon.com/images/I/61cMeogK8gL.jpg\n",
            "92: https://m.media-amazon.com/images/I/811VfR10yxL.jpg\n",
            "93: https://m.media-amazon.com/images/I/71WLYfmMqQL.jpg\n",
            "94: https://m.media-amazon.com/images/I/61Dq3LRei9L.jpg\n",
            "95: https://m.media-amazon.com/images/I/71XK5d3Oh9L.jpg\n",
            "96: https://m.media-amazon.com/images/I/61kyBEJYDeL.jpg\n",
            "97: https://m.media-amazon.com/images/I/71uQmsTESvL.jpg\n",
            "98: https://m.media-amazon.com/images/I/71jG8BOi4WL.jpg\n",
            "99: https://m.media-amazon.com/images/I/61390hosjFL.jpg\n",
            "100: https://m.media-amazon.com/images/I/71PDbPb275L.jpg\n",
            "101: https://m.media-amazon.com/images/I/71YiRw3e1lL.jpg\n",
            "102: https://m.media-amazon.com/images/I/719poaEkdEL.jpg\n",
            "103: https://m.media-amazon.com/images/I/41njJJg-ANL.jpg\n",
            "104: https://m.media-amazon.com/images/I/71qEriwsbIL.jpg\n",
            "105: https://m.media-amazon.com/images/I/514M5CrBK4L.jpg\n",
            "106: https://m.media-amazon.com/images/I/61qOr-yqaVL.jpg\n",
            "107: https://m.media-amazon.com/images/I/61xxqfM2EwL.jpg\n",
            "108: https://m.media-amazon.com/images/I/81yG9eUKvxL.jpg\n",
            "109: https://m.media-amazon.com/images/I/61FMOl299lL.jpg\n",
            "110: https://m.media-amazon.com/images/I/41Kn+YOyPjL.jpg\n",
            "111: https://m.media-amazon.com/images/I/51q9OE6hfgL.jpg\n",
            "112: https://m.media-amazon.com/images/I/51T1Kh7WWGL.jpg\n",
            "113: https://m.media-amazon.com/images/I/71G8XyPqcIL.jpg\n",
            "114: https://m.media-amazon.com/images/I/61Hhju+qn9L.jpg\n",
            "115: https://m.media-amazon.com/images/I/51Alw-4+zJL.jpg\n",
            "116: https://m.media-amazon.com/images/I/81l6zfwKG7L.jpg\n",
            "117: https://m.media-amazon.com/images/I/71eATPu53YL.jpg\n",
            "118: https://m.media-amazon.com/images/I/81R8CrWXthL.jpg\n",
            "119: https://m.media-amazon.com/images/I/71qiWPgPcUS.jpg\n",
            "120: https://m.media-amazon.com/images/I/81nyHjPXg-L.jpg\n",
            "121: https://m.media-amazon.com/images/I/71EREAIkJZS.jpg\n",
            "122: https://m.media-amazon.com/images/I/61bpzE0p4yL.jpg\n",
            "123: https://m.media-amazon.com/images/I/71yqAwAikaL.jpg\n",
            "124: https://m.media-amazon.com/images/I/61431aMH6cL.jpg\n",
            "125: https://m.media-amazon.com/images/I/71lxjbXw9bL.jpg\n",
            "126: https://m.media-amazon.com/images/I/71cziTM6TfL.jpg\n",
            "127: https://m.media-amazon.com/images/I/71Btb49O2dL.jpg\n",
            "128: https://m.media-amazon.com/images/I/51QhV+Ox86L.jpg\n",
            "129: https://m.media-amazon.com/images/I/51ArM1PP7WL.jpg\n",
            "130: https://m.media-amazon.com/images/I/51F+K7Zx9fL.jpg\n",
            "131: https://m.media-amazon.com/images/I/51u2vv6e8yL.jpg\n",
            "132: https://m.media-amazon.com/images/I/71PexaOBvoL.jpg\n",
            "133: https://m.media-amazon.com/images/I/81uHTyMDa7L.jpg\n",
            "134: https://m.media-amazon.com/images/I/81x+p0LzKbL.jpg\n",
            "135: https://m.media-amazon.com/images/I/71kCYzCu0UL.jpg\n",
            "136: https://m.media-amazon.com/images/I/81F2B83meFL.jpg\n",
            "137: https://m.media-amazon.com/images/I/71KFQ3qt4gL.jpg\n",
            "138: https://m.media-amazon.com/images/I/71Oo4M3ApxL.jpg\n",
            "139: https://m.media-amazon.com/images/I/71Oo4M3ApxL.jpg\n",
            "140: https://m.media-amazon.com/images/I/61lE-I9cVuL.jpg\n",
            "141: https://m.media-amazon.com/images/I/71+FvzD14RL.jpg\n",
            "142: https://m.media-amazon.com/images/I/414maJ3RUML.jpg\n",
            "143: https://m.media-amazon.com/images/I/7158CO+v3kL.jpg\n",
            "144: https://m.media-amazon.com/images/I/71NoP+8HnqS.jpg\n",
            "145: https://m.media-amazon.com/images/I/51K0v0zo-wL.jpg\n",
            "146: https://m.media-amazon.com/images/I/51H6vfyBqML.jpg\n",
            "147: https://m.media-amazon.com/images/I/81gzy3-ZlML.jpg\n",
            "148: https://m.media-amazon.com/images/I/71mKPQGo8wL.jpg\n",
            "149: https://m.media-amazon.com/images/I/81puuiKhs5L.jpg\n",
            "150: https://m.media-amazon.com/images/I/61CLKFwJa4L.jpg\n",
            "151: https://m.media-amazon.com/images/I/615v9WaUIuL.jpg\n",
            "152: https://m.media-amazon.com/images/I/71P0BToikAL.jpg\n",
            "153: https://m.media-amazon.com/images/I/61HisZt9hcL.jpg\n",
            "154: https://m.media-amazon.com/images/I/81JGAcnf39L.jpg\n",
            "155: https://m.media-amazon.com/images/I/31o8WywVeTL.jpg\n",
            "156: https://m.media-amazon.com/images/I/61Ik5NY4ExL.jpg\n",
            "157: https://m.media-amazon.com/images/I/71pKB7-3itL.jpg\n",
            "158: https://m.media-amazon.com/images/I/71PGzqxh-EL.jpg\n",
            "159: https://m.media-amazon.com/images/I/71uqF3qqsuL.jpg\n",
            "160: https://m.media-amazon.com/images/I/61vdMgkasML.jpg\n",
            "161: https://m.media-amazon.com/images/I/81xeFGugw6L.jpg\n",
            "162: https://m.media-amazon.com/images/I/71Ye12U8zRL.jpg\n",
            "163: https://m.media-amazon.com/images/I/61UjKZyijBL.jpg\n",
            "164: https://m.media-amazon.com/images/I/61v1IQDiIbL.jpg\n",
            "165: https://m.media-amazon.com/images/I/71WffHaS-QL.jpg\n",
            "166: https://m.media-amazon.com/images/I/61mLRVKOr3L.jpg\n",
            "167: https://m.media-amazon.com/images/I/619W5ruX5xL.jpg\n",
            "168: https://m.media-amazon.com/images/I/51YZWIRgY0L.jpg\n",
            "169: https://m.media-amazon.com/images/I/81Qf73SxLaL.jpg\n",
            "170: https://m.media-amazon.com/images/I/81cEIIPti-L.jpg\n",
            "171: https://m.media-amazon.com/images/I/71ciI6RbOqL.jpg\n",
            "172: https://m.media-amazon.com/images/I/816L-kPJGyL.jpg\n",
            "173: https://m.media-amazon.com/images/I/7185b+0uzML.jpg\n",
            "174: https://m.media-amazon.com/images/I/7185b+0uzML.jpg\n",
            "175: https://m.media-amazon.com/images/I/71In1fvGSwL.jpg\n",
            "176: https://m.media-amazon.com/images/I/8146TN-qDgL.jpg\n",
            "177: https://m.media-amazon.com/images/I/71bA7Tj2y5L.jpg\n",
            "178: https://m.media-amazon.com/images/I/51ZpARXmu+L.jpg\n",
            "179: https://m.media-amazon.com/images/I/81ZyvlRczjL.jpg\n",
            "180: https://m.media-amazon.com/images/I/81zuZujBfyL.jpg\n",
            "181: https://m.media-amazon.com/images/I/71mi7h+tZmL.jpg\n",
            "182: https://m.media-amazon.com/images/I/71A7RiB2IIS.jpg\n",
            "183: https://m.media-amazon.com/images/I/61UkMSPhLSS.jpg\n",
            "184: https://m.media-amazon.com/images/I/616QEdZeLGL.jpg\n",
            "185: https://m.media-amazon.com/images/I/61nvPvyO7kL.jpg\n",
            "186: https://m.media-amazon.com/images/I/71ihnkVAoCL.jpg\n",
            "187: https://m.media-amazon.com/images/I/51WaQdTFyhL.jpg\n",
            "188: https://m.media-amazon.com/images/I/71k9HXFp5VL.jpg\n",
            "189: https://m.media-amazon.com/images/I/81hbfdu3UaL.jpg\n",
            "190: https://m.media-amazon.com/images/I/815pYcvCCeL.jpg\n",
            "191: https://m.media-amazon.com/images/I/615roHaokEL.jpg\n",
            "192: https://m.media-amazon.com/images/I/71JXfZLNJjL.jpg\n",
            "193: https://m.media-amazon.com/images/I/71yQq9I3yzL.jpg\n",
            "194: https://m.media-amazon.com/images/I/718M5ODio0L.jpg\n",
            "195: https://m.media-amazon.com/images/I/61lpwH0qHbL.jpg\n",
            "196: https://m.media-amazon.com/images/I/712sZRVe98L.jpg\n",
            "197: https://m.media-amazon.com/images/I/71d+dz7ogkL.jpg\n",
            "198: https://m.media-amazon.com/images/I/51WSQa1ygML.jpg\n",
            "199: https://m.media-amazon.com/images/I/71QR6ELoPnL.jpg\n",
            "200: https://m.media-amazon.com/images/I/71cO37WLcCL.jpg\n",
            "201: https://m.media-amazon.com/images/I/71k0T1lkazL.jpg\n",
            "202: https://m.media-amazon.com/images/I/61qfHDESRQL.jpg\n",
            "203: https://m.media-amazon.com/images/I/61QC4Kt6FgL.jpg\n",
            "204: https://m.media-amazon.com/images/I/81+ZDpWM6aL.jpg\n",
            "205: https://m.media-amazon.com/images/I/711unoPoAUL.jpg\n",
            "206: https://m.media-amazon.com/images/I/91yjUjUz1PL.jpg\n",
            "207: https://m.media-amazon.com/images/I/61iyjkBOWwL.jpg\n",
            "208: https://m.media-amazon.com/images/I/81bWfMuySqL.jpg\n",
            "209: https://m.media-amazon.com/images/I/81cNMlJ3rUL.jpg\n",
            "210: https://m.media-amazon.com/images/I/71V8xeIdY8L.jpg\n",
            "211: https://m.media-amazon.com/images/I/81QVNxEt5jL.jpg\n",
            "212: https://m.media-amazon.com/images/I/61rzdBIml6S.jpg\n",
            "213: https://m.media-amazon.com/images/I/71XLo+kfY4S.jpg\n",
            "214: https://m.media-amazon.com/images/I/61GnRPsq7eS.jpg\n",
            "215: https://m.media-amazon.com/images/I/71L-+M3VVPL.jpg\n",
            "216: https://m.media-amazon.com/images/I/81OX3LrynvL.jpg\n",
            "217: https://m.media-amazon.com/images/I/71CgwBBpm2L.jpg\n",
            "218: https://m.media-amazon.com/images/I/61uEVvHFcnL.jpg\n",
            "219: https://m.media-amazon.com/images/I/6186qz73QDL.jpg\n",
            "220: https://m.media-amazon.com/images/I/51-GFfHUt5L.jpg\n",
            "221: https://m.media-amazon.com/images/I/71wManz+q7L.jpg\n",
            "222: https://m.media-amazon.com/images/I/71rBE9Nt9sL.jpg\n",
            "223: https://m.media-amazon.com/images/I/61NpAba1eLL.jpg\n",
            "224: https://m.media-amazon.com/images/I/81GfAC59d9L.jpg\n",
            "225: https://m.media-amazon.com/images/I/71BkkuPYJFL.jpg\n",
            "226: https://m.media-amazon.com/images/I/61k7TzX5kYL.jpg\n",
            "227: https://m.media-amazon.com/images/I/81hGUpAFNJL.jpg\n",
            "228: https://m.media-amazon.com/images/I/71iSbwHDcdL.jpg\n",
            "229: https://m.media-amazon.com/images/I/81BxHI-QPIL.jpg\n",
            "230: https://m.media-amazon.com/images/I/71WaRSgdUyL.jpg\n",
            "231: https://m.media-amazon.com/images/I/61cEFL6Y49L.jpg\n",
            "232: https://m.media-amazon.com/images/I/817S4LJR21L.jpg\n",
            "233: https://m.media-amazon.com/images/I/81V9hFKQT4L.jpg\n",
            "234: https://m.media-amazon.com/images/I/81i7biHKFUL.jpg\n",
            "235: https://m.media-amazon.com/images/I/9146CDDyS1L.jpg\n",
            "236: https://m.media-amazon.com/images/I/61zbBwJJ86L.jpg\n",
            "237: https://m.media-amazon.com/images/I/61g2MIPw-SL.jpg\n",
            "238: https://m.media-amazon.com/images/I/61rViW3qEDL.jpg\n",
            "239: https://m.media-amazon.com/images/I/41fYovCueJL.jpg\n",
            "240: https://m.media-amazon.com/images/I/61dL1hqmPTL.jpg\n",
            "241: https://m.media-amazon.com/images/I/61ErAvSUnML.jpg\n",
            "242: https://m.media-amazon.com/images/I/41J6cTfYEJL.jpg\n",
            "243: https://m.media-amazon.com/images/I/51FHIAeaWpL.jpg\n",
            "244: https://m.media-amazon.com/images/I/51egZNPkbmL.jpg\n",
            "245: https://m.media-amazon.com/images/I/61ptgk7Z6NL.jpg\n",
            "246: https://m.media-amazon.com/images/I/61mR0nvTi2L.jpg\n",
            "247: https://m.media-amazon.com/images/I/71kKyflqh-L.jpg\n",
            "248: https://m.media-amazon.com/images/I/81jraWFAHEL.jpg\n",
            "249: https://m.media-amazon.com/images/I/61q8BFKyG5L.jpg\n",
            "250: https://m.media-amazon.com/images/I/711pKODV8fL.jpg\n",
            "251: https://m.media-amazon.com/images/I/818ZG7g9hHL.jpg\n",
            "252: https://m.media-amazon.com/images/I/818ZG7g9hHL.jpg\n",
            "253: https://m.media-amazon.com/images/I/719SXCcE+yL.jpg\n",
            "254: https://m.media-amazon.com/images/I/71KGqjaeU3L.jpg\n",
            "255: https://m.media-amazon.com/images/I/81pIxwIlH1L.jpg\n",
            "256: https://m.media-amazon.com/images/I/81dTA+JL8hL.jpg\n",
            "257: https://m.media-amazon.com/images/I/91YXnPoBr9L.jpg\n",
            "258: https://m.media-amazon.com/images/I/61ssSqT8LBL.jpg\n",
            "259: https://m.media-amazon.com/images/I/71rMtEbiU2L.jpg\n",
            "260: https://m.media-amazon.com/images/I/71DngBpcvfL.jpg\n",
            "261: https://m.media-amazon.com/images/I/81eYKrxwPeL.jpg\n",
            "262: https://m.media-amazon.com/images/I/41yG6r50SGL.jpg\n",
            "263: https://m.media-amazon.com/images/I/61CKA8YZZQL.jpg\n",
            "264: https://m.media-amazon.com/images/I/71GGzJw4lJL.jpg\n",
            "265: https://m.media-amazon.com/images/I/71s4ixwJ35L.jpg\n",
            "266: https://m.media-amazon.com/images/I/61oJbgINwyL.jpg\n",
            "267: https://m.media-amazon.com/images/I/71xNXOBXbeL.jpg\n",
            "268: https://m.media-amazon.com/images/I/81ILq5SlokL.jpg\n",
            "269: https://m.media-amazon.com/images/I/61qBC3QCpKL.jpg\n",
            "270: https://m.media-amazon.com/images/I/41jz25vrqpL.jpg\n",
            "271: https://m.media-amazon.com/images/I/81fRIl3bhHL.jpg\n",
            "272: https://m.media-amazon.com/images/I/61ZcOamhAXL.jpg\n",
            "273: https://m.media-amazon.com/images/I/6179WU7pPnL.jpg\n",
            "274: https://m.media-amazon.com/images/I/711UcLF1AOL.jpg\n",
            "275: https://m.media-amazon.com/images/I/71bEyocs6cL.jpg\n",
            "276: https://m.media-amazon.com/images/I/81P0F4kSO5L.jpg\n",
            "277: https://m.media-amazon.com/images/I/61xt0+F24LL.jpg\n",
            "278: https://m.media-amazon.com/images/I/41o+Ah16aOL.jpg\n",
            "279: https://m.media-amazon.com/images/I/61t+5wQl08L.jpg\n",
            "280: https://m.media-amazon.com/images/I/61jznP3TP-L.jpg\n",
            "281: https://m.media-amazon.com/images/I/41UtmzUICML.jpg\n",
            "282: https://m.media-amazon.com/images/I/71N+e+6NXUL.jpg\n",
            "283: https://m.media-amazon.com/images/I/71wSp5zkmOL.jpg\n",
            "284: https://m.media-amazon.com/images/I/61dRC9mLuLL.jpg\n",
            "285: https://m.media-amazon.com/images/I/718Y1zul73L.jpg\n",
            "286: https://m.media-amazon.com/images/I/61HmWvlaCgS.jpg\n",
            "287: https://m.media-amazon.com/images/I/61hmMEg2+JL.jpg\n",
            "288: https://m.media-amazon.com/images/I/717jdsjET2S.jpg\n",
            "289: https://m.media-amazon.com/images/I/71UctMVz2wL.jpg\n",
            "290: https://m.media-amazon.com/images/I/71Y2sN5CZ2L.jpg\n",
            "291: https://m.media-amazon.com/images/I/71TIH9xp14L.jpg\n",
            "292: https://m.media-amazon.com/images/I/51MfQdcFO4L.jpg\n",
            "293: https://m.media-amazon.com/images/I/61IZwm4favL.jpg\n",
            "294: https://m.media-amazon.com/images/I/71Cpa4ITxCL.jpg\n",
            "295: https://m.media-amazon.com/images/I/71XKEn+9WSL.jpg\n",
            "296: https://m.media-amazon.com/images/I/71Yl8r0WgHL.jpg\n",
            "297: https://m.media-amazon.com/images/I/71VHlwzHsIL.jpg\n",
            "298: https://m.media-amazon.com/images/I/81aU1hA-LKL.jpg\n",
            "299: https://m.media-amazon.com/images/I/911ddalhbYL.jpg\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "for (idx, (url, id, ent_type, ent_val)) in enumerate(sample.values):\n",
        "  print(f\"{idx}: {url}\")\n",
        "  image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "  text = f\"List the {ent_type} measurement in this image. In the format of 100 grams or 1000 kgs, etc. List only the measurement, nothing else. Print <NO> if the measurement cant be found\"\n",
        "\n",
        "  label = ent_val\n",
        "  inputs = processor(images=image, text=text, return_tensors=\"pt\")\n",
        "  labels = processor(text=label, return_tensors=\"pt\").input_ids\n",
        "\n",
        "  inputs[\"labels\"] = labels\n",
        "  outputs = model(**inputs)\n",
        "  loss = outputs.loss\n",
        "  loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oo33u-8QQd1C",
        "outputId": "d059513e-aaa2-4624-e7e7-8db47f906685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 | height : https://m.media-amazon.com/images/I/110EibNyclL.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30000\n",
            "1 | width : https://m.media-amazon.com/images/I/11TU2clswzL.jpg\n",
            "no\n",
            "2 | height : https://m.media-amazon.com/images/I/11TU2clswzL.jpg\n",
            "no\n",
            "3 | depth : https://m.media-amazon.com/images/I/11TU2clswzL.jpg\n",
            "no\n",
            "4 | depth : https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg\n",
            "no\n",
            "5 | height : https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg\n",
            "no\n",
            "6 | width : https://m.media-amazon.com/images/I/11gHj8dhhrL.jpg\n",
            "no\n",
            "7 | height : https://m.media-amazon.com/images/I/11lshEUmCrL.jpg\n",
            "30000\n",
            "8 | width : https://m.media-amazon.com/images/I/21+i52HRW4L.jpg\n",
            "10\n",
            "9 | height : https://m.media-amazon.com/images/I/21-LmSmehZL.jpg\n",
            "100 m\n",
            "10 | item_weight : https://m.media-amazon.com/images/I/213oP6n7jtL.jpg\n",
            "1. 0\n",
            "11 | width : https://m.media-amazon.com/images/I/213wY3gUsmL.jpg\n",
            "30 cm\n",
            "12 | depth : https://m.media-amazon.com/images/I/214CLs1oznL.jpg\n",
            "10000\n",
            "13 | height : https://m.media-amazon.com/images/I/214CLs1oznL.jpg\n",
            "10000\n",
            "14 | width : https://m.media-amazon.com/images/I/214CLs1oznL.jpg\n",
            "10\n",
            "15 | item_weight : https://m.media-amazon.com/images/I/216rjgJHAeL.jpg\n",
            "1000 pounds\n",
            "16 | maximum_weight_recommendation : https://m.media-amazon.com/images/I/2174yonQBtL.jpg\n",
            "3000\n",
            "17 | item_weight : https://m.media-amazon.com/images/I/218BCzgKxuL.jpg\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f65379bda058>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, pixel_values, attention_mask, interpolate_pos_encoding, **generate_kwargs)\u001b[0m\n\u001b[1;32m   1414\u001b[0m         )\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1416\u001b[0;31m         outputs = self.text_decoder.generate(\n\u001b[0m\u001b[1;32m   1417\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbos_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m             \u001b[0meos_token_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep_token_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2024\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2025\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2982\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msynced_gpus\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthis_peer_finished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, return_logits, is_decoder, reduction)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m    872\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, encoder_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, is_decoder)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 )\n\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    437\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip_text.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/blip/modeling_blip_text.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Inference\n",
        "for (idx, (index, url, id, ent_type)) in enumerate(test_sample.values):\n",
        "  print(f\"{idx} | {ent_type} : {url}\")\n",
        "  image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "  text = f\"List the {ent_type} measurement in this image. In the format of 100 grams or 1000 kgs, etc. List only the measurement, nothing else\"\n",
        "\n",
        "  inputs = processor(images=image, text=text, return_tensors=\"pt\")\n",
        "  outputs = model.generate(**inputs)\n",
        "  print(processor.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBdPIlZIWR3p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
