{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "import requests\n",
    "import pandas as pd\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\n",
    "    \"http://localhost:5000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/16 20:32:45 INFO mlflow.tracking.fluent: Experiment with name 'check-connection' does not exist. Creating a new experiment.\n",
      "2024/09/16 20:32:45 INFO mlflow.tracking._tracking_service.client: üèÉ View run sneaky-fawn-598 at: http://localhost:5000/#/experiments/588219251072499462/runs/e62831d71d4041019de56e8a38be633e.\n",
      "2024/09/16 20:32:45 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/588219251072499462.\n"
     ]
    }
   ],
   "source": [
    "exp = mlflow.set_experiment(\"check-connection\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"foo\", 1)\n",
    "    mlflow.log_metric(\"bar\", 2)\n",
    "\n",
    "mlflow.delete_experiment(exp.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/paligemma-3b-mix-224\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8fcea5cef348ec9f620abfd7d38834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id).eval()\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "train_sample = train_df.sample(1000)\n",
    "test_sample = test_df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_resize(image, target_size):\n",
    "    return image.resize(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "def read_image(url, target_size):\n",
    "    image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
    "    image = crop_and_resize(image, target_size)\n",
    "    image = np.array(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"index\": [], \"prediction\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (idx, (index, url, id, ent_type)) in enumerate(test_sample.values):\n",
    "    print(f\"{idx}: {url}\")\n",
    "    image = read_image(url, (224, 224))\n",
    "\n",
    "    if ent_type == \"item_weight\" or ent_type == \"maximum_weight_recommendation\":\n",
    "        ent_type = \"net weight\"\n",
    "\n",
    "    prompt = f'answer en What is the item {ent_type}?\\n'\n",
    "\n",
    "    model_inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generation = model.generate(**model_inputs, max_new_tokens=100, do_sample=False)\n",
    "        generation = generation[0][input_len:]\n",
    "        output = processor.decode(generation, skip_special_tokens=True)\n",
    "        print(output)\n",
    "\n",
    "    result = pd.concat([result, pd.DataFrame({\"index\": [idx], \"prediction\": [output.split(\"\\n\")[0]]})], ignore_index=True)\n",
    "\n",
    "    if idx == 5000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
